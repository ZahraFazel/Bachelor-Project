{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils\n!pip install segmentation_models_pytorch\n!pip install captum\n!pip install albumentations\n!pip install gdown \nimport gdown \nurl = 'https://drive.google.com/uc?id=1hO4j-rZgm_ZB_OlJFNeQQRYCj9jpldII' \noutput = 'data.zip'\ngdown.download(url, output)\nurl = 'https://drive.google.com/uc?id=1kxR97Vpy_trLiulEY2o4pcfYEdVk7QOI' \noutput = 'best_model.pth'\ngdown.download(url, output)\n!unzip data.zip","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-30T16:59:24.394693Z","iopub.execute_input":"2022-01-30T16:59:24.394990Z","iopub.status.idle":"2022-01-30T17:01:10.031600Z","shell.execute_reply.started":"2022-01-30T16:59:24.394910Z","shell.execute_reply":"2022-01-30T17:01:10.030726Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport os\nfrom collections import defaultdict, OrderedDict\nimport shutil\nimport time\nimport copy\nimport math\nimport random\nfrom imutils import paths\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom numpy import unravel_index\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nfrom torchvision import transforms\nfrom torchvision import datasets\n\nfrom PIL import *\nimport albumentations as A\nimport skimage\n\nimport segmentation_models_pytorch as smp\nprint(torch.cuda.is_available())","metadata":{"id":"SUEOkB6EoUAA","outputId":"d0151148-10bd-4b6b-98f3-27d3aec82203","execution":{"iopub.status.busy":"2022-01-30T17:01:10.033995Z","iopub.execute_input":"2022-01-30T17:01:10.034220Z","iopub.status.idle":"2022-01-30T17:01:22.260577Z","shell.execute_reply.started":"2022-01-30T17:01:10.034192Z","shell.execute_reply":"2022-01-30T17:01:22.259679Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.mkdir('./HAM10000/train')\nos.mkdir('./HAM10000/train/images')\nos.mkdir('./HAM10000/train/masks')\nos.mkdir('./HAM10000/val')\nos.mkdir('./HAM10000/val/images')\nos.mkdir('./HAM10000/val/masks')\nos.mkdir('./HAM10000/test')\nos.mkdir('./HAM10000/test/images')\nos.mkdir('./HAM10000/test/masks')\nimages = sorted(list(paths.list_files('./HAM10000/images/', contains=\"jpg\")))\nmasks = sorted(list(paths.list_files('./HAM10000/masks/', contains=\"png\")))\na = np.array(range(1, 10015))\ntrain, val, test = a[:8000], a[8000:9000], a[9000:]\nfor i in train:\n    img_file_name = images[i].split('/')[-1]\n    mask_file_name = masks[i].split('/')[-1]\n    shutil.copy('./HAM10000/images/' + img_file_name, './HAM10000/train/images/' + img_file_name)\n    shutil.copy('./HAM10000/masks/' + mask_file_name, './HAM10000/train/masks/' + mask_file_name)\nfor i in val:\n    img_file_name = images[i].split('/')[-1]\n    mask_file_name = masks[i].split('/')[-1]\n    shutil.copy('./HAM10000/images/' + img_file_name, './HAM10000/val/images/' + img_file_name)\n    shutil.copy('./HAM10000/masks/' + mask_file_name, './HAM10000/val/masks/' + mask_file_name)\nfor i in test:\n    img_file_name = images[i].split('/')[-1]\n    mask_file_name = masks[i].split('/')[-1]\n    shutil.copy('./HAM10000/images/' + img_file_name, './HAM10000/test/images/' + img_file_name)\n    shutil.copy('./HAM10000/masks/' + mask_file_name, './HAM10000/test/masks/' + mask_file_name)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T17:01:22.262312Z","iopub.execute_input":"2022-01-30T17:01:22.262792Z","iopub.status.idle":"2022-01-30T17:01:55.892277Z","shell.execute_reply.started":"2022-01-30T17:01:22.262749Z","shell.execute_reply":"2022-01-30T17:01:55.891506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def visualize(**images):\n    n_images = len(images)\n    f, axarr = plt.subplots(1, n_images, figsize=(4 * n_images,4))\n    for idx, (name, image) in enumerate(images.items()):\n        if image.shape[0] == 3 or image.shape[0] == 2:\n            axarr[idx].imshow(np.squeeze(image.permute(1, 2, 0)))\n        else: \n            axarr[idx].imshow(np.squeeze(image))\n        axarr[idx].set_title(name.replace('_',' ').title(), fontsize=20)\n    plt.show()\n    \nclass SkinDataset(Dataset):\n    def __init__(self, images, masks, augmentations=None):   \n        self.input_images = images\n        self.target_masks = masks\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.input_images)\n    \n    def __getitem__(self, idx): \n        img = Image.open(os.path.join(self.input_images[idx])).convert('RGB')\n        mask = Image.open(os.path.join(self.target_masks[idx])).convert('RGB')\n        img = transforms.Compose([transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST), transforms.ToTensor()])(img)\n        mask = transforms.Compose([transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST), transforms.Grayscale(), transforms.ToTensor()])(mask)\n        img = img.permute((1, 2, 0))\n        mask = mask.permute((1, 2, 0))\n        img = img.cpu().detach().numpy()\n        mask = mask.cpu().detach().numpy()\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n        \n        img = torch.tensor(img, dtype=torch.float)\n        img = img.permute((2, 0, 1))\n        mask = torch.tensor(mask, dtype=torch.float)\n        mask = mask.permute((2, 0, 1))\n        \n        return [img, mask]\n\n    \ntrain_batch_size = 64\nval_batch_size = 16\ntest_batch_size = 16\nnum_workers = 2\n\n# main_dir = '/media/external_3TB/3TB/rasekh/fazel/KVASIR/'\n# main_dir = '/content/drive/My Drive/KVASIR/'\n# main_dir = 'KVASIR/'\nmain_dir = './HAM10000/'\n\ntrain_images = sorted(list(paths.list_files(main_dir + 'train/images/', contains=\"jpg\")))\nval_images = sorted(list(paths.list_files(main_dir + 'val/images/', contains=\"jpg\")))\ntest_images = sorted(list(paths.list_files(main_dir + 'test/images/', contains=\"jpg\")))\n\ntrain_masks = sorted(list(paths.list_files(main_dir + 'train/masks/', contains=\"png\")))\nval_masks = sorted(list(paths.list_files(main_dir + 'val/masks/', contains=\"png\")))\ntest_masks = sorted(list(paths.list_files(main_dir + 'test/masks/', contains=\"png\")))\n\naugmentations = A.Compose({\n        A.HorizontalFlip(p=0.5),\n        A.Rotate(limit=(-90, 90)),\n        A.VerticalFlip(p=0.5),\n        A.Transpose(p=0.5),\n        A.GaussianBlur(p=0.5),\n        A.augmentations.geometric.transforms.Affine(scale=(0.9, 1.1), translate_percent=0.1)\n})\n\ndataset = {\n    'train': SkinDataset(train_images, train_masks, augmentations), \n    'val': SkinDataset(val_images, val_masks, None), \n    'test': SkinDataset(test_images, test_masks, None)\n}\n\ndataloader = {\n    'train': DataLoader(dataset['train'], batch_size=train_batch_size, shuffle=True, num_workers=num_workers),\n    'val': DataLoader(dataset['val'], batch_size=val_batch_size, shuffle=True, num_workers=num_workers),\n    'test': DataLoader(dataset['test'], batch_size=test_batch_size, shuffle=False, num_workers=num_workers)\n}\n\nimage, mask = dataset['train'][random.randint(0, len(dataset['train'])-1)]\nprint(image.shape, image.min(), image.max())\nprint(mask.shape, mask.min(), mask.max())\nvisualize(\n    original_image = image,\n    grund_truth_mask = mask,\n    lesion = skimage.segmentation.mark_boundaries(image.permute(1, 2, 0).detach().cpu().numpy(), mask.detach().cpu().numpy()[0].astype(np.int64), color=(0, 0, 1), mode='thick')\n)","metadata":{"id":"dOKGH2G-oUAL","execution":{"iopub.status.busy":"2022-01-30T17:01:55.894283Z","iopub.execute_input":"2022-01-30T17:01:55.894576Z","iopub.status.idle":"2022-01-30T17:01:56.865437Z","shell.execute_reply.started":"2022-01-30T17:01:55.894538Z","shell.execute_reply":"2022-01-30T17:01:56.638696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n\n    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n        super(UNet, self).__init__()\n\n        features = init_features\n        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n\n        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n        self.conv = nn.Conv2d(in_channels=features, out_channels=out_channels, kernel_size=1)\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool1(enc1))\n        enc3 = self.encoder3(self.pool2(enc2))\n        enc4 = self.encoder4(self.pool3(enc3))\n\n        bottleneck = self.bottleneck(self.pool4(enc4))\n\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.decoder4(dec4)\n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n        return torch.sigmoid(self.conv(dec1))\n\n    @staticmethod\n    def _block(in_channels, features, name):\n        return nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        name + \"conv1\",\n                        nn.Conv2d(\n                            in_channels=in_channels,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu1\", nn.ReLU(inplace=True)),\n                    (\n                        name + \"conv2\",\n                        nn.Conv2d(\n                            in_channels=features,\n                            out_channels=features,\n                            kernel_size=3,\n                            padding=1,\n                            bias=False,\n                        ),\n                    ),\n                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n                    (name + \"relu2\", nn.ReLU(inplace=True)),\n                ]\n            )\n        )\n\nclass Loss(smp.utils.base.Loss):\n    def __init__(self, eps=1.0, activation=None, **kwargs):\n        super().__init__(**kwargs)\n        self.eps = eps\n        self.activation = smp.base.modules.Activation(activation)\n        self._name = 'loss'\n\n    def forward(self, y_pr, y_gt):\n        y_pr = self.activation(y_pr)\n        return (1 - smp.utils.functional.iou(y_pr, y_gt, eps=self.eps, threshold=0.3)) + (1 - smp.utils.functional.f_score(y_pr, y_gt, beta=1, eps=self.eps, threshold=0.3)) + nn.functional.binary_cross_entropy(y_pr, y_gt)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:37:25.62396Z","iopub.execute_input":"2022-01-30T12:37:25.624242Z","iopub.status.idle":"2022-01-30T12:37:41.388971Z","shell.execute_reply.started":"2022-01-30T12:37:25.624202Z","shell.execute_reply":"2022-01-30T12:37:41.388246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training = True\nepochs = 100\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\n\nloss = Loss()\n\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.3),\n    smp.utils.metrics.Fscore(threshold=0.3),\n    smp.utils.metrics.Accuracy(threshold=0.3)\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.0005),\n])\n\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n    optimizer, T_0=1, T_mult=2, eta_min=0.00001,\n)\n\ntrain_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)\n\nif training:\n\n    best_model = {'loss': 0.0, 'iou_score': 0.0, 'fscore': 0.0, 'accuracy': 0.0}\n    train_logs_list, valid_logs_list = [], []\n\n    for i in range(0, epochs):\n        print('\\nEpoch: {}'.format(i))\n        train_logs = train_epoch.run(dataloader['train'])\n        valid_logs = valid_epoch.run(dataloader['val'])\n        train_logs_list.append(train_logs)\n        valid_logs_list.append(valid_logs)\n\n        if best_model['iou_score'] < valid_logs['iou_score']:\n            torch.save(model, main_dir + 'best_model.pth')\n            best_model['loss'] = valid_logs['loss']\n            best_model['iou_score'] = valid_logs['iou_score']\n            best_model['fscore'] = valid_logs['fscore']\n            best_model['accuracy'] = valid_logs['accuracy']\n            print('Model saved!')","metadata":{"id":"fIlVc7OapTuX","scrolled":true,"execution":{"iopub.status.busy":"2022-01-30T12:37:41.393551Z","iopub.execute_input":"2022-01-30T12:37:41.395551Z","iopub.status.idle":"2022-01-30T16:20:30.479826Z","shell.execute_reply.started":"2022-01-30T12:37:41.395511Z","shell.execute_reply":"2022-01-30T16:20:30.478839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(best_model)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T16:28:43.365542Z","iopub.execute_input":"2022-01-30T16:28:43.366111Z","iopub.status.idle":"2022-01-30T16:28:43.44818Z","shell.execute_reply.started":"2022-01-30T16:28:43.366061Z","shell.execute_reply":"2022-01-30T16:28:43.447231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs_df = pd.DataFrame(train_logs_list)\nvalid_logs_df = pd.DataFrame(valid_logs_list)","metadata":{"id":"_B-5qHn-rO6_","outputId":"8c60ef1d-897e-4e5b-a94e-15ed79d5c870","execution":{"iopub.status.busy":"2022-01-30T16:28:46.205851Z","iopub.execute_input":"2022-01-30T16:28:46.206378Z","iopub.status.idle":"2022-01-30T16:28:46.281456Z","shell.execute_reply.started":"2022-01-30T16:28:46.206339Z","shell.execute_reply":"2022-01-30T16:28:46.280747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.loss.tolist(), lw=1, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.loss.tolist(), lw=1, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Loss', fontsize=20)\nplt.title('Loss Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('loss_plot.png')\nplt.show()","metadata":{"id":"zr2PPzT9oUAS","outputId":"aa60af71-7353-4469-d4de-88627abe7819","execution":{"iopub.status.busy":"2022-01-30T16:29:27.252336Z","iopub.execute_input":"2022-01-30T16:29:27.252612Z","iopub.status.idle":"2022-01-30T16:29:27.656903Z","shell.execute_reply.started":"2022-01-30T16:29:27.252573Z","shell.execute_reply":"2022-01-30T16:29:27.656205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=1, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=1, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('IoU Score', fontsize=20)\nplt.title('IoU Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('iou_score_plot.png')\nplt.show()","metadata":{"id":"L5arr_lnoUAU","outputId":"1b6cba91-25a1-4335-c45a-4aecbe88480f","execution":{"iopub.status.busy":"2022-01-30T16:29:43.188844Z","iopub.execute_input":"2022-01-30T16:29:43.189125Z","iopub.status.idle":"2022-01-30T16:29:43.582909Z","shell.execute_reply.started":"2022-01-30T16:29:43.189095Z","shell.execute_reply":"2022-01-30T16:29:43.58211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.fscore.tolist(), lw=1, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.fscore.tolist(), lw=1, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('F1 Score', fontsize=20)\nplt.title('F1 Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('fscore_plot.png')\nplt.show()","metadata":{"id":"ZLrsVTU9oUAV","outputId":"1071d01d-b193-4909-d4d0-885c015bcc7d","execution":{"iopub.status.busy":"2022-01-30T16:29:52.157386Z","iopub.execute_input":"2022-01-30T16:29:52.157927Z","iopub.status.idle":"2022-01-30T16:29:52.568065Z","shell.execute_reply.started":"2022-01-30T16:29:52.157887Z","shell.execute_reply":"2022-01-30T16:29:52.567399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.accuracy.tolist(), lw=1, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.accuracy.tolist(), lw=1, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Accuracy Score', fontsize=20)\nplt.title('Accuracy Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.savefig('accuracy_plot.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T16:29:58.188779Z","iopub.execute_input":"2022-01-30T16:29:58.189111Z","iopub.status.idle":"2022-01-30T16:29:58.60308Z","shell.execute_reply.started":"2022-01-30T16:29:58.189047Z","shell.execute_reply":"2022-01-30T16:29:58.602409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbest_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\nbest_model = torch.load('./best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T17:01:56.866521Z","iopub.execute_input":"2022-01-30T17:01:56.866823Z","iopub.status.idle":"2022-01-30T17:02:36.364366Z","shell.execute_reply.started":"2022-01-30T17:01:56.866784Z","shell.execute_reply":"2022-01-30T17:02:36.363606Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nbest_model.eval()\n\nIOUs = []\nF1s = []\npredictions = []\n\nwith torch.no_grad():\n    for i, (inputs, labels) in enumerate(dataloader['test']):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        pred_mask = best_model(inputs)\n\n        for i in range(len(inputs)):\n            test_image = inputs[i]\n            test_mask = labels[i]\n            predMask = pred_mask[i]\n            \n            iou = smp.utils.functional.iou(predMask, test_mask, threshold=0.3)\n            IOUs.append(iou.cpu().detach())\n\n            f1 = smp.utils.functional.f_score(predMask, test_mask, threshold=0.3)\n            F1s.append(f1.cpu().detach())\n            \n            predMask = torch.where(predMask >= 0.3, 1, 0)\n            predictions.append(predMask)\n\n#             visualize(\n#                 original_image = test_image.cpu(),\n#                 ground_truth_mask = test_mask.cpu(),\n#                 predicted_mask = predMask.cpu(),\n#                 lesion = skimage.segmentation.mark_boundaries(test_image.permute(1, 2, 0).detach().cpu().numpy(), predMask.detach().cpu().numpy()[0].astype(np.int64), color=(0, 0, 1), mode='thick')\n#             )","metadata":{"id":"pj0hVHuioUAW","outputId":"aae25f2b-f76f-40e0-9825-4f61117fa483","scrolled":true,"execution":{"iopub.status.busy":"2022-01-30T17:02:36.365859Z","iopub.execute_input":"2022-01-30T17:02:36.366107Z","iopub.status.idle":"2022-01-30T17:02:52.742240Z","shell.execute_reply.started":"2022-01-30T17:02:36.366073Z","shell.execute_reply":"2022-01-30T17:02:52.741378Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('Test IOU: ' + str(np.mean(IOUs)))\nprint('Test F1: ' + str(np.mean(F1s)))","metadata":{"id":"8IfIxNS8oUAX","outputId":"18e27cec-5791-4717-d384-c8f852533409","execution":{"iopub.status.busy":"2022-01-30T17:02:52.743753Z","iopub.execute_input":"2022-01-30T17:02:52.744844Z","iopub.status.idle":"2022-01-30T17:02:52.832889Z","shell.execute_reply.started":"2022-01-30T17:02:52.744799Z","shell.execute_reply":"2022-01-30T17:02:52.832105Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(np.min(IOUs), np.min(F1s), np.min(Accuracies))\nprint(np.max(IOUs), np.max(F1s), np.max(Accuracies))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T14:44:20.830264Z","iopub.execute_input":"2022-01-17T14:44:20.830586Z","iopub.status.idle":"2022-01-17T14:44:20.898808Z","shell.execute_reply.started":"2022-01-17T14:44:20.830528Z","shell.execute_reply":"2022-01-17T14:44:20.898062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = torch.cat(predictions).cpu().detach().numpy()","metadata":{"id":"073CMCO-lHE9","execution":{"iopub.status.busy":"2021-11-22T16:33:22.910004Z","iopub.execute_input":"2021-11-22T16:33:22.910633Z","iopub.status.idle":"2021-11-22T16:33:23.129179Z","shell.execute_reply.started":"2021-11-22T16:33:22.910569Z","shell.execute_reply":"2021-11-22T16:33:23.128111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = np.argmax(IOUs)\nimg, mask = dataset['test'][index]\npred_mask = predictions[index]\npred_mask = torch.Tensor(pred_mask.reshape((1, pred_mask.shape[0], pred_mask.shape[1]))).cpu().detach()\nf, axarr = plt.subplots(1, 3, figsize=(12, 4))\naxarr[0].imshow(np.squeeze(img.permute(1, 2, 0)))\naxarr[1].imshow(np.squeeze(mask.permute(1, 2, 0)))\naxarr[2].imshow(np.squeeze(pred_mask.permute(1, 2, 0)))\nplt.show()","metadata":{"id":"IdGAgqiUlWHY","outputId":"828ce917-6a60-454f-f035-a34095810f67","execution":{"iopub.status.busy":"2021-11-22T16:33:29.816316Z","iopub.execute_input":"2021-11-22T16:33:29.816602Z","iopub.status.idle":"2021-11-22T16:33:30.465844Z","shell.execute_reply.started":"2021-11-22T16:33:29.816571Z","shell.execute_reply":"2021-11-22T16:33:30.464968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from captum.attr import visualization as viz\nfrom captum.attr import LayerGradCam, FeatureAblation, LayerActivation, LayerAttribution","metadata":{"execution":{"iopub.status.busy":"2021-11-22T11:32:11.354941Z","iopub.execute_input":"2021-11-22T11:32:11.355212Z","iopub.status.idle":"2021-11-22T11:32:11.46331Z","shell.execute_reply.started":"2021-11-22T11:32:11.355181Z","shell.execute_reply":"2021-11-22T11:32:11.462475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThis wrapper computes the segmentation model output and sums the pixel scores for\nall pixels predicted as each class, returning a tensor with a single value for\neach class. This makes it easier to attribute with respect to a single output\nscalar, as opposed to an individual pixel output attribution.\n\"\"\"\ndef agg_segmentation_wrapper(out):\n#     model_out = fcn(inp)['out']\n    # Creates binary matrix with 1 for original argmax class for each pixel\n    # and 0 otherwise. Note that this may change when the input is ablated\n    # so we use the original argmax predicted above, out_max.\n    out_max = torch.argmax(out, dim=1, keepdim=True)\n    selected_inds = torch.zeros_like(out[0:1]).scatter_(1, out_max, 1)\n    return (model_out * selected_inds).sum(dim=(2,3))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T11:34:25.707509Z","iopub.execute_input":"2021-11-22T11:34:25.708183Z","iopub.status.idle":"2021-11-22T11:34:25.780245Z","shell.execute_reply.started":"2021-11-22T11:34:25.708147Z","shell.execute_reply":"2021-11-22T11:34:25.779441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgc = LayerGradCam(agg_segmentation_wrapper, model.encoder1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T11:34:27.733445Z","iopub.execute_input":"2021-11-22T11:34:27.734118Z","iopub.status.idle":"2021-11-22T11:34:27.800637Z","shell.execute_reply.started":"2021-11-22T11:34:27.734079Z","shell.execute_reply":"2021-11-22T11:34:27.799856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n# normalized_inp = normalize(img).unsqueeze(0).to(device)\ngc_attr = lgc.attribute(img.to(device), target=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T11:34:30.54522Z","iopub.execute_input":"2021-11-22T11:34:30.545972Z","iopub.status.idle":"2021-11-22T11:34:30.694255Z","shell.execute_reply.started":"2021-11-22T11:34:30.545938Z","shell.execute_reply":"2021-11-22T11:34:30.693274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"la = LayerActivation(agg_segmentation_wrapper, model.encoder1)\nactivation = la.attribute(normalized_inp)\nprint(\"Input Shape:\", normalized_inp.shape)\nprint(\"Layer Activation Shape:\", activation.shape)\nprint(\"Layer GradCAM Shape:\", gc_attr.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz.visualize_image_attr(gc_attr[0].cpu().permute(1,2,0).detach().numpy(),sign=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsampled_gc_attr = LayerAttribution.interpolate(gc_attr,normalized_inp.shape[2:])\nprint(\"Upsampled Shape:\",upsampled_gc_attr.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz.visualize_image_attr_multiple(upsampled_gc_attr[0].cpu().permute(1,2,0).detach().numpy(),original_image=preproc_img.permute(1,2,0).numpy(),signs=[\"all\", \"positive\", \"negative\"],methods=[\"original_image\", \"blended_heat_map\",\"blended_heat_map\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_without_train = (1 - (out_max == 19).float())[0].cpu() * preproc_img\nplt.imshow(img_without_train.permute(1,2,0))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fa = FeatureAblation(agg_segmentation_wrapper)\nfa_attr = fa.attribute(normalized_inp, feature_mask=out_max, perturbations_per_eval=2, target=6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz.visualize_image_attr(fa_attr[0].cpu().detach().permute(1,2,0).numpy(),sign=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fa_attr_without_max = (1 - (out_max == 6).float())[0] * fa_attr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz.visualize_image_attr(fa_attr_without_max[0].cpu().detach().permute(1,2,0).numpy(),sign=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}