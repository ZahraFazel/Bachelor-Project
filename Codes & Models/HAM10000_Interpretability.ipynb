{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Download Data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-01T17:49:27.186972Z",
          "iopub.execute_input": "2022-02-01T17:49:27.188079Z",
          "iopub.status.idle": "2022-02-01T17:50:53.075601Z",
          "shell.execute_reply.started": "2022-02-01T17:49:27.187917Z",
          "shell.execute_reply": "2022-02-01T17:50:53.07448Z"
        },
        "id": "9DpgwhC6_lul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils\n",
        "!pip install segmentation_models_pytorch\n",
        "!pip install captum\n",
        "!pip install albumentations\n",
        "!pip install gdown \n",
        "import gdown \n",
        "url = 'https://drive.google.com/uc?id=1m8UaoRojKfxTitNQ92bgcWpw5yIxO6U7' \n",
        "output = 'data.zip'\n",
        "gdown.download(url, output)\n",
        "url = 'https://drive.google.com/19v_xbtE3G7oTI97UUMfJ5eO2la8OLpLW' \n",
        "output = 'best_model.pth'\n",
        "gdown.download(url, output)\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-02-02T23:33:21.241840Z",
          "iopub.execute_input": "2022-02-02T23:33:21.242712Z",
          "iopub.status.idle": "2022-02-02T23:35:09.640520Z",
          "shell.execute_reply.started": "2022-02-02T23:33:21.242583Z",
          "shell.execute_reply": "2022-02-02T23:35:09.639755Z"
        },
        "trusted": true,
        "id": "ocUNEBU6_luv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "from collections import defaultdict, OrderedDict\n",
        "import shutil\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "import random\n",
        "from imutils import paths\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import unravel_index\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "from PIL import *\n",
        "import albumentations as A\n",
        "import skimage\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import GuidedGradCam, Saliency, DeepLift, GuidedBackprop, LayerGradCam, LayerDeepLift, LayerAttribution\n",
        "from captum.metrics import sensitivity_max, infidelity\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "SUEOkB6EoUAA",
        "execution": {
          "iopub.status.busy": "2022-02-02T23:35:09.642931Z",
          "iopub.execute_input": "2022-02-02T23:35:09.643261Z",
          "iopub.status.idle": "2022-02-02T23:35:28.930575Z",
          "shell.execute_reply.started": "2022-02-02T23:35:09.643200Z",
          "shell.execute_reply": "2022-02-02T23:35:28.929756Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "0nrSTl9A_lu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(**images):\n",
        "    n_images = len(images)\n",
        "    f, axarr = plt.subplots(1, n_images, figsize=(4 * n_images,4))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        if image.shape[0] == 3 or image.shape[0] == 2:\n",
        "            axarr[idx].imshow(np.squeeze(image.permute(1, 2, 0)))\n",
        "        else: \n",
        "            axarr[idx].imshow(np.squeeze(image))\n",
        "        axarr[idx].set_title(name.replace('_',' ').title(), fontsize=20)\n",
        "    plt.show()\n",
        "    \n",
        "class SkinDataset(Dataset):\n",
        "    def __init__(self, images, masks, augmentations=None):   \n",
        "        self.input_images = images\n",
        "        self.target_masks = masks\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        img = Image.open(os.path.join(self.input_images[idx])).convert('RGB')\n",
        "        mask = Image.open(os.path.join(self.target_masks[idx])).convert('RGB')\n",
        "        img = transforms.Compose([transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST), transforms.ToTensor()])(img)\n",
        "        mask = transforms.Compose([transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST), transforms.Grayscale(), transforms.ToTensor()])(mask)\n",
        "        img = img.permute((1, 2, 0))\n",
        "        mask = mask.permute((1, 2, 0))\n",
        "        img = img.cpu().detach().numpy()\n",
        "        mask = mask.cpu().detach().numpy()\n",
        "        \n",
        "        if self.augmentations:\n",
        "            augmented = self.augmentations(image=img, mask=mask)\n",
        "            img = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "        \n",
        "        img = torch.tensor(img, dtype=torch.float)\n",
        "        img = img.permute((2, 0, 1))\n",
        "        mask = torch.tensor(mask, dtype=torch.float)\n",
        "        mask = mask.permute((2, 0, 1))\n",
        "        \n",
        "        return [img, mask]\n",
        "\n",
        "    \n",
        "train_batch_size = 64\n",
        "val_batch_size = 16\n",
        "test_batch_size = 16\n",
        "num_workers = 2\n",
        "\n",
        "main_dir = './HAM10000/'\n",
        "\n",
        "train_images = sorted(list(paths.list_files(main_dir + 'train/images/', contains=\"jpg\")))\n",
        "val_images = sorted(list(paths.list_files(main_dir + 'val/images/', contains=\"jpg\")))\n",
        "test_images = sorted(list(paths.list_files(main_dir + 'test/images/', contains=\"jpg\")))\n",
        "\n",
        "train_masks = sorted(list(paths.list_files(main_dir + 'train/masks/', contains=\"png\")))\n",
        "val_masks = sorted(list(paths.list_files(main_dir + 'val/masks/', contains=\"png\")))\n",
        "test_masks = sorted(list(paths.list_files(main_dir + 'test/masks/', contains=\"png\")))\n",
        "\n",
        "augmentations = A.Compose({\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=(-90, 90)),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Transpose(p=0.5),\n",
        "        A.GaussianBlur(p=0.5),\n",
        "        A.augmentations.geometric.transforms.Affine(scale=(0.9, 1.1), translate_percent=0.1)\n",
        "})\n",
        "\n",
        "dataset = {\n",
        "    'train': SkinDataset(train_images, train_masks, augmentations), \n",
        "    'val': SkinDataset(val_images, val_masks, None), \n",
        "    'test': SkinDataset(test_images, test_masks, None)\n",
        "}\n",
        "\n",
        "dataloader = {\n",
        "    'train': DataLoader(dataset['train'], batch_size=train_batch_size, shuffle=True, num_workers=num_workers),\n",
        "    'val': DataLoader(dataset['val'], batch_size=val_batch_size, shuffle=True, num_workers=num_workers),\n",
        "    'test': DataLoader(dataset['test'], batch_size=test_batch_size, shuffle=False, num_workers=num_workers)\n",
        "}\n",
        "\n",
        "image, mask = dataset['train'][random.randint(0, len(dataset['train'])-1)]\n",
        "print(image.shape, image.min(), image.max())\n",
        "print(mask.shape, mask.min(), mask.max())\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    grund_truth_mask = mask,\n",
        "    lesion = skimage.segmentation.mark_boundaries(image.permute(1, 2, 0).detach().cpu().numpy(), mask.detach().cpu().numpy()[0].astype(np.int64), color=(0, 0, 1), mode='thick')\n",
        ")"
      ],
      "metadata": {
        "id": "dOKGH2G-oUAL",
        "execution": {
          "iopub.status.busy": "2022-02-02T23:35:28.933076Z",
          "iopub.execute_input": "2022-02-02T23:35:28.933388Z",
          "iopub.status.idle": "2022-02-02T23:35:29.637314Z",
          "shell.execute_reply.started": "2022-02-02T23:35:28.933348Z",
          "shell.execute_reply": "2022-02-02T23:35:29.633540Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "M6Rn1QoyVceT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(smp.utils.base.Loss):\n",
        "    def __init__(self, eps=1.0, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "        self.activation = smp.base.modules.Activation(activation)\n",
        "        self._name = 'loss'\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        y_pr = self.activation(y_pr)\n",
        "        return (1 - smp.utils.functional.iou(y_pr, y_gt, eps=self.eps, threshold=0.3)) + (1 - smp.utils.functional.f_score(y_pr, y_gt, beta=1, eps=self.eps, threshold=0.3)) + nn.functional.binary_cross_entropy(y_pr, y_gt)"
      ],
      "metadata": {
        "id": "sbdW1rkxVfGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = True\n",
        "epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
        "\n",
        "loss = Loss()\n",
        "\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.3),\n",
        "    smp.utils.metrics.Fscore(threshold=0.3)\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.0005),\n",
        "])\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=0.00001,\n",
        ")\n",
        "\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=device,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "if training:\n",
        "\n",
        "    best_model = {'loss': 0.0, 'iou_score': 0.0, 'fscore': 0.0}\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, epochs):\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(dataloader['train'])\n",
        "        valid_logs = valid_epoch.run(dataloader['val'])\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        if best_model['iou_score'] < valid_logs['iou_score']:\n",
        "            torch.save(model, main_dir + 'best_model.pth')\n",
        "            best_model['loss'] = valid_logs['loss']\n",
        "            best_model['iou_score'] = valid_logs['iou_score']\n",
        "            best_model['fscore'] = valid_logs['fscore']\n",
        "            print('Model saved!')"
      ],
      "metadata": {
        "id": "zcwaJpwDVi-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model)"
      ],
      "metadata": {
        "id": "qRDj4iGQVmk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_logs_df = pd.DataFrame(train_logs_list)\n",
        "valid_logs_df = pd.DataFrame(valid_logs_list)"
      ],
      "metadata": {
        "id": "_EgeS9PsVpGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.loss.tolist(), lw=1, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.loss.tolist(), lw=1, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('Loss', fontsize=20)\n",
        "plt.title('Loss Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('loss_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6w-a8k1FVrCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=1, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=1, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('IoU Score', fontsize=20)\n",
        "plt.title('IoU Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('iou_score_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ao_rOU_4VtIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.fscore.tolist(), lw=1, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.fscore.tolist(), lw=1, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('F1 Score', fontsize=20)\n",
        "plt.title('F1 Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('fscore_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Ks3AJELVxNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.accuracy.tolist(), lw=1, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.accuracy.tolist(), lw=1, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('Accuracy Score', fontsize=20)\n",
        "plt.title('Accuracy Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('accuracy_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xVUdwVsMVz4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Best Model"
      ],
      "metadata": {
        "id": "uh8GCuPH_lu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# best_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
        "best_model = torch.load('./best_model.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T23:35:29.638982Z",
          "iopub.execute_input": "2022-02-02T23:35:29.639244Z",
          "iopub.status.idle": "2022-02-02T23:35:41.265356Z",
          "shell.execute_reply.started": "2022-02-02T23:35:29.639194Z",
          "shell.execute_reply": "2022-02-02T23:35:41.264555Z"
        },
        "trusted": true,
        "id": "1OF9O7Yp_lu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "bgD07unM_lvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "best_model.eval()\n",
        "\n",
        "IOUs = []\n",
        "F1s = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloader['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        pred_mask = best_model(inputs)\n",
        "\n",
        "        for i in range(len(inputs)):\n",
        "            test_image = inputs[i]\n",
        "            test_mask = labels[i]\n",
        "            predMask = pred_mask[i]\n",
        "            \n",
        "            iou = smp.utils.functional.iou(predMask, test_mask, threshold=0.3)\n",
        "            IOUs.append(iou.cpu().detach())\n",
        "\n",
        "            f1 = smp.utils.functional.f_score(predMask, test_mask, threshold=0.3)\n",
        "            F1s.append(f1.cpu().detach())\n",
        "            \n",
        "            predMask = torch.where(predMask >= 0.3, 1, 0)"
      ],
      "metadata": {
        "id": "pj0hVHuioUAW",
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-02-02T23:35:41.266946Z",
          "iopub.execute_input": "2022-02-02T23:35:41.267198Z",
          "iopub.status.idle": "2022-02-02T23:35:57.923718Z",
          "shell.execute_reply.started": "2022-02-02T23:35:41.267162Z",
          "shell.execute_reply": "2022-02-02T23:35:57.922821Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test IOU: ' + str(np.mean(IOUs)))\n",
        "print('Test F1: ' + str(np.mean(F1s)))"
      ],
      "metadata": {
        "id": "8IfIxNS8oUAX",
        "execution": {
          "iopub.status.busy": "2022-02-02T23:35:57.928588Z",
          "iopub.execute_input": "2022-02-02T23:35:57.933483Z",
          "iopub.status.idle": "2022-02-02T23:35:58.027033Z",
          "shell.execute_reply.started": "2022-02-02T23:35:57.933395Z",
          "shell.execute_reply": "2022-02-02T23:35:58.026301Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpret"
      ],
      "metadata": {
        "id": "xC0yJHKX_lvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_border(mask):\n",
        "    border = skimage.segmentation.find_boundaries(mask.detach().cpu().numpy(), mode='outer').astype(np.uint8)\n",
        "    indices = np.where(border == 1)\n",
        "    indices = np.concatenate((indices[0][...,np.newaxis],indices[1][...,np.newaxis],indices[2][...,np.newaxis]),axis=1)\n",
        "    return list(map(tuple, indices))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T23:41:17.122290Z",
          "iopub.execute_input": "2022-02-02T23:41:17.122620Z",
          "iopub.status.idle": "2022-02-02T23:41:17.173399Z",
          "shell.execute_reply.started": "2022-02-02T23:41:17.122581Z",
          "shell.execute_reply": "2022-02-02T23:41:17.172706Z"
        },
        "trusted": true,
        "id": "smuyLIZd_lvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attr(method, image, targets):\n",
        "    maps = list()\n",
        "    for target in targets:\n",
        "        if isinstance(method, DeepLift):\n",
        "            attr = method.attribute(image.to(device), target=target, return_convergence_delta=False)\n",
        "        else:\n",
        "            attr = method.attribute(image.to(device), target=target)\n",
        "        if attr.shape[2] < image.shape[2]:\n",
        "            upsampled_attr = LayerAttribution.interpolate(attr, (image.shape[2], image.shape[3]))\n",
        "        else:\n",
        "            upsampled_attr = attr\n",
        "        maps.append(np.mean(upsampled_attr.detach().cpu().numpy()[0], 0, keepdims=True)[0])\n",
        "    return np.array(maps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T23:41:17.479814Z",
          "iopub.execute_input": "2022-02-02T23:41:17.480074Z",
          "iopub.status.idle": "2022-02-02T23:41:17.533112Z",
          "shell.execute_reply.started": "2022-02-02T23:41:17.480044Z",
          "shell.execute_reply": "2022-02-02T23:41:17.532284Z"
        },
        "trusted": true,
        "id": "9ZpB3NEC_lvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agg_attr(out, size):\n",
        "    i = np.zeros(out.shape)\n",
        "    for k in range(out.shape[0]):\n",
        "        a = np.max(np.abs(out[k]))\n",
        "        a = a if a != 0 else 1\n",
        "        i[k] = out[k] / a\n",
        "    return np.sum(i, 0).reshape(size, size, 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T23:41:21.870789Z",
          "iopub.execute_input": "2022-02-02T23:41:21.871045Z",
          "iopub.status.idle": "2022-02-02T23:41:21.922271Z",
          "shell.execute_reply.started": "2022-02-02T23:41:21.871015Z",
          "shell.execute_reply": "2022-02-02T23:41:21.921427Z"
        },
        "trusted": true,
        "id": "69zJLJIy_lvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_model(model, image, image_name):\n",
        "    figure_size = (5, 5)\n",
        "    img_cpu = image.cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_batch = image.unsqueeze(0)\n",
        "    pred_mask = model(img_batch.to(device))[0]\n",
        "    binary_mask = torch.where(pred_mask >= 0.3, 1, 0)\n",
        "    \n",
        "    sm = Saliency(model)\n",
        "    sm_out = get_attr(sm, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(sm_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Saliency.png', format='png', dpi=1200)\n",
        "\n",
        "    gbp = GuidedBackprop(model)\n",
        "    gbp_out = get_attr(gbp, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(gbp_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Guided Backpropagation.png', format='png', dpi=1200)\n",
        "    \n",
        "    ggc = GuidedGradCam(model, model.conv)\n",
        "    ggc_out = get_attr(ggc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ggc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Guided Grad-CAM.png', format='png', dpi=1200)\n",
        "    \n",
        "    dl = DeepLift(model)\n",
        "    dl_out = get_attr(dl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(dl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_DeepLift.png', format='png', dpi=1200)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T23:41:43.079699Z",
          "iopub.execute_input": "2022-02-02T23:41:43.079992Z",
          "iopub.status.idle": "2022-02-02T23:41:43.139017Z",
          "shell.execute_reply.started": "2022-02-02T23:41:43.079942Z",
          "shell.execute_reply": "2022-02-02T23:41:43.138285Z"
        },
        "trusted": true,
        "id": "Lju3ld-C_lvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_layers_with_gradcam(model, image, image_name):\n",
        "    figure_size = (5, 5)\n",
        "    img_cpu = image.cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_batch = image.unsqueeze(0)\n",
        "    pred_mask = model(img_batch.to(device))[0]\n",
        "    binary_mask = torch.where(pred_mask >= 0.3, 1, 0)\n",
        "\n",
        "    lgc = LayerGradCam(model, model.encoder1)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"],\n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Encoder1\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Encoder1.png', format='png', dpi=1200)\n",
        "    \n",
        "    lgc = LayerGradCam(model, model.encoder2)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Encoder2\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Encoder2.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.encoder3)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Encoder3\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Encoder3.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.encoder4)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Encoder4\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Encoder4.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.bottleneck)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Bottleneck\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Bottleneck.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.decoder4)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Decoder4\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Decoder4.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.decoder3)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Decoder3\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Decoder3.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.decoder2)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Decoder2\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Decoder2.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.decoder1)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Decoder1\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_Decoder1.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    lgc = LayerGradCam(model, model.conv)\n",
        "    lgc_out = get_attr(lgc, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(lgc_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"Grad-CAM - Last Layer\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer Grad-CAM_LastLayer.png', format='png', dpi=1200)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T20:59:05.388476Z",
          "iopub.execute_input": "2022-02-02T20:59:05.39103Z",
          "iopub.status.idle": "2022-02-02T20:59:05.513135Z",
          "shell.execute_reply.started": "2022-02-02T20:59:05.39099Z",
          "shell.execute_reply": "2022-02-02T20:59:05.512039Z"
        },
        "trusted": true,
        "id": "Df2Q_MWp_lvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_layers_with_deeplift(model, image, image_name):\n",
        "    figure_size = (5, 5)\n",
        "    img_cpu = image.cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_batch = image.unsqueeze(0)\n",
        "    pred_mask = model(img_batch.to(device))[0]\n",
        "    binary_mask = torch.where(pred_mask >= 0.3, 1, 0)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.encoder1)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Encoder1\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Encoder1.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.encoder2)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Encoder2\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Encoder2.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.encoder3)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Encoder3\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Encoder3.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.encoder4)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Encoder4\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Encoder4.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.bottleneck)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Bottleneck\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Bottleneck.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.decoder4)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Decoder4\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Decoder4.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.decoder3)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Decoder3\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Decoder3.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.decoder2)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu,signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Decoder2\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Decoder2.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.decoder1)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Decoder1\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_Decoder1.png', format='png', dpi=1200)\n",
        "                                      \n",
        "    ldl = LayerDeepLift(model, model.conv)\n",
        "    ldl_out = get_attr(ldl, img_batch, get_border(binary_mask))\n",
        "    figure, _ = viz.visualize_image_attr_multiple(agg_attr(ldl_out, image.shape[1]), original_image=img_cpu, signs=[\"all\"], \n",
        "                                                  methods=[\"blended_heat_map\"], show_colorbar=True, titles=[\"DeepLift - Last Layer\"], fig_size=figure_size)\n",
        "    figure.savefig(image_name + '_Layer DeepLift_LastLayer.png', format='png', dpi=1200)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T20:59:05.518517Z",
          "iopub.execute_input": "2022-02-02T20:59:05.518809Z",
          "iopub.status.idle": "2022-02-02T20:59:05.713137Z",
          "shell.execute_reply.started": "2022-02-02T20:59:05.51877Z",
          "shell.execute_reply": "2022-02-02T20:59:05.71167Z"
        },
        "trusted": true,
        "id": "NM08qpSy_lvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in (-np.array(IOUs)).argsort()[:5]:\n",
        "    img, _ = dataset['test'][idx]\n",
        "    img_name = 'ham10000_' + str(idx + 9001)\n",
        "    interpret_model(best_model, img, img_name)\n",
        "    interpret_layers_with_gradcam(best_model, img, img_name)\n",
        "    interpret_layers_with_deeplift(best_model, img, img_name)\n",
        "    !zip {img_name + '.zip'} {img_name + '_*.png'}\n",
        "    !rm *.png"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-02-02T23:56:44.650977Z",
          "iopub.execute_input": "2022-02-02T23:56:44.651296Z",
          "iopub.status.idle": "2022-02-03T00:02:23.521292Z",
          "shell.execute_reply.started": "2022-02-02T23:56:44.651257Z",
          "shell.execute_reply": "2022-02-03T00:02:23.520345Z"
        },
        "trusted": true,
        "id": "1LdFbFKw_lvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Interpretions"
      ],
      "metadata": {
        "id": "S4OSbxE-_lvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_fn(inputs):\n",
        "    noise = torch.tensor(np.random.normal(0, 0.001, inputs.shape)).float().to(device)\n",
        "    return noise, inputs - noise"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T21:01:22.181138Z",
          "iopub.execute_input": "2022-02-02T21:01:22.181811Z",
          "iopub.status.idle": "2022-02-02T21:01:22.239965Z",
          "shell.execute_reply.started": "2022-02-02T21:01:22.181768Z",
          "shell.execute_reply": "2022-02-02T21:01:22.238878Z"
        },
        "trusted": true,
        "id": "BQc91aeb_lvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infidelity_score_model_interpretations(model, image):\n",
        "    \n",
        "    methods = [Saliency(model), GuidedBackprop(model), GuidedGradCam(model, model.conv), DeepLift(model)]\n",
        "    infidelity_scores = [0, 0, 0, 0]\n",
        "    \n",
        "    img_cpu = image.cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_batch = image.unsqueeze(0)\n",
        "    pred_mask = model(img_batch.to(device))[0]\n",
        "    binary_mask = torch.where(pred_mask >= 0.3, 1, 0)\n",
        "    border = get_border(binary_mask)\n",
        "    \n",
        "    for i in range(len(methods)):\n",
        "        infid = 0\n",
        "        for j in range(len(border)):\n",
        "            if isinstance(methods[i], DeepLift):\n",
        "                attribution = methods[i].attribute(img_batch.to(device), target=border[j], return_convergence_delta=False)\n",
        "            else:\n",
        "                attribution = methods[i].attribute(img_batch.to(device), target=border[j])\n",
        "            infid += infidelity(model, perturb_fn, img_batch.to(device), attribution, n_perturb_samples=1)\n",
        "        infid /= len(border)\n",
        "        infidelity_scores[i] += infid\n",
        "    \n",
        "    return infidelity_scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T21:01:24.660698Z",
          "iopub.execute_input": "2022-02-02T21:01:24.661489Z",
          "iopub.status.idle": "2022-02-02T21:01:24.716005Z",
          "shell.execute_reply.started": "2022-02-02T21:01:24.661431Z",
          "shell.execute_reply": "2022-02-02T21:01:24.715192Z"
        },
        "trusted": true,
        "id": "4db-H6g1_lvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infidelity_score_layer_interpretations(model, test_dataset):\n",
        "    \n",
        "    methods = [[LayerGradCam(model, model.encoder1), LayerGradCam(model, model.encoder2), LayerGradCam(model, model.encoder3), \n",
        "                LayerGradCam(model, model.encoder4), LayerGradCam(model, model.bottleneck), LayerGradCam(model, model.decoder4), \n",
        "                LayerGradCam(model, model.decoder3), LayerGradCam(model, model.decoder2), LayerGradCam(model, model.decoder1), \n",
        "                LayerGradCam(model, model.conv)], \n",
        "               [LayerDeepLift(model, model.encoder1), LayerDeepLift(model, model.encoder2), LayerDeepLift(model, model.encoder3), \n",
        "                LayerDeepLift(model, model.encoder4), LayerDeepLift(model, model.bottleneck), LayerDeepLift(model, model.decoder4), \n",
        "                LayerDeepLift(model, model.decoder3), LayerDeepLift(model, model.decoder2), LayerDeepLift(model, model.decoder1), \n",
        "                LayerDeepLift(model, model.conv)]]\n",
        "    infidelity_scores = [0, 0]\n",
        "    \n",
        "    img_cpu = image.cpu().permute(1, 2, 0).detach().numpy()\n",
        "    img_batch = image.unsqueeze(0)\n",
        "    pred_mask = model(img_batch.to(device))[0]\n",
        "    binary_mask = torch.where(pred_mask >= 0.3, 1, 0)\n",
        "    border = get_border(binary_mask)\n",
        "        \n",
        "    for i in range(len(methods)):\n",
        "        infid = 0\n",
        "        for k in range(len(methods[i])):\n",
        "            layer_infid = 0\n",
        "            for j in range(len(border)):\n",
        "                attribution = methods[i][k].attribute(img_batch.to(device), target=border[j])\n",
        "                if attribution.shape[2] < image.shape[1]:\n",
        "                    attribution = LayerAttribution.interpolate(attribution, (image.shape[1], image.shape[2]))\n",
        "                if isinstance(methods[i][k], LayerDeepLift):\n",
        "                    attribution = torch.mean(attribution, 1, keepdims=True)\n",
        "                layer_infid += infidelity(model, perturb_fn, img_batch.to(device), attribution.repeat(1, 3, 1, 1), n_perturb_samples=1)\n",
        "            layer_infid /= len(border)\n",
        "            infid += layer_infid\n",
        "        infid /= len(methods[i])\n",
        "        infidelity_scores[i] += infid\n",
        "    \n",
        "    return infidelity_scores"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T21:01:28.231396Z",
          "iopub.execute_input": "2022-02-02T21:01:28.231817Z",
          "iopub.status.idle": "2022-02-02T21:01:28.294333Z",
          "shell.execute_reply.started": "2022-02-02T21:01:28.23178Z",
          "shell.execute_reply": "2022-02-02T21:01:28.293614Z"
        },
        "trusted": true,
        "id": "h-N-80Wt_lvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_infid = []\n",
        "for idx in range(len(dataset['test'])):\n",
        "    img, _ = dataset['test'][idx]\n",
        "    model_infid.append(infidelity_score_model_interpretations(best_model, img))\n",
        "print(np.mean(model_infid))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-02T16:41:15.222382Z",
          "iopub.execute_input": "2022-02-02T16:41:15.223176Z",
          "iopub.status.idle": "2022-02-02T17:07:46.126458Z",
          "shell.execute_reply.started": "2022-02-02T16:41:15.223126Z",
          "shell.execute_reply": "2022-02-02T17:07:46.125515Z"
        },
        "trusted": true,
        "id": "2RYZAAbc_lvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_infid = []\n",
        "for idx in range(len(dataset['test'])):\n",
        "    img, _ = dataset['test'][idx]\n",
        "    layer_infid.append(infidelity_score_layer_interpretations(best_model, img))\n",
        "print(np.mean(layer_infid))"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2022-02-02T21:02:14.124136Z",
          "iopub.execute_input": "2022-02-02T21:02:14.124603Z",
          "iopub.status.idle": "2022-02-02T22:33:13.161013Z",
          "shell.execute_reply.started": "2022-02-02T21:02:14.124552Z",
          "shell.execute_reply": "2022-02-02T22:33:13.160235Z"
        },
        "trusted": true,
        "id": "kP-W5Ipt_lva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}